First author: Neil Leonard
nleonard5@wisc.edu
Second author: Yewon Lee
ylee578@wisc.edu
Third author: George Liu
gliu84@wisc.edu


Introduction:
	Machine learning is an exciting field of research, partly due to the wealth of techniques and
	 plethora of questions to be answered. When navigating such an open field, to make pertinent 
	 and interesting contributions we are prioritizing conciseness. As such, we will be asking 
	 ourselves: how  “weak” is a “weak learner”. Using the ADA boosting algorithm, we will be 
	 tuning hyper parameters of the algorithm to find a the weakness threshold at which algorithm
	  converges on a meaningful classification algorithm. For our weak learner, we will be using 
	  a fully-connected CNN against the MNIST data set. These are standard resources used in the 
	  field, which will help us create clear statements about our finding, as we will not get lost in the implementation of a more exotic technique or data set. 




Motivation:  Often times machine learning enthusiasts are eager to find the optimal model, 
then go about tuning their parameters through “guess-and-check” method. However, very sophisticated or complex models 
may suffer from high run-time or the curse of high dimensionality. We can avoid these problems while 
still maximizing predictive power by using ADA boosting, a set of “weak learners” is chained together to make a more 
successful algorithm. While the rest of the algorithm is clearly defined, the definition of what 
a “weak learner” is vague and up to user. In our project we hope to quantify this idea by ranging 
our hyper parameters of the “weak learner” and observing how these values affect the 
classification power of the overall algorithm. By doing this, we should be able to see at what 
thresholds these hyper parameters create a successful algorithm.



Evaluation:
There are two important evaluation criteria to be responsible for: the error of each “weak 
learner” and the strength of the overall algorithm. For the individual “weak learners” we will 
use a traditional classification error as prescribed by the ADA algorithm. As for the overall 
effectiveness of the algorithm, this is a more subtle question. Due to the nature of question we 
are looking to answer, we are interested the full range that the overall classification accuracy 
of algorithm takes. In particular, we are interested in how changing the tuning parameters turns 
a “weak” algorithm (one with above random guessing but not completely accurate) to a “strong” 
algorithm (one with a high classification accuracy). A successful implantation of the answering 
our question will show a smooth transition from “weak” to “strong” algorithm. The hyper parameters used to demonstrate this transition will the training size of the CNNs and the number of "weak learners" used in the ADA implementation (i.e the k value from the figure above)


Resources:
As described above, we will implanting a fully-connected Convolutional Neural Network and 
training it with the MNIST data set. Due to the relative simplicity of this implementation, there 
is many options to take. Depending on the difficulty of implementation, we will either be using 
the standard machine learning package PyTorch, or the open source code from Michael Nielsen’s web 
book Neural Networks and Deep Learning. The latter is attractive in that we will have access to 
every line of code, making it easier to modify for our specifications. The simplicity of our 
algorithm may make it possible to not use a more powerful library. 


Contributions:
The following are the major steps in the project:
Preprocessing of the MNIST data
Postprocessing of the data (graphing and analysis)
Creating of the overall code of our implementation 
Using that code to create the data for the report
